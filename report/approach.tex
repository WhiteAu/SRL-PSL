To avoid the expense of creating training corpora, we employ a weak-learning approach in which the predicates in an existing training corpus are aligned to relations in a large external database, and instances of the database relations guide the search for novel training examples within another new corpus.  If a learner is then be trained over a combination of the original training corpus and the new training examples, we hope that the resulting model has improved accuracy over the new corpus, compared to a model trained on the original training corpus alone.

Previous efforts to automatically find novel SRL training examples exist [FÃ¼rstenau et al, 2012], but have not leveraged an external structured data source.  Weak supervision for relation extraction has been done previously [Mintz et al, 2009], but to our knowledge it was not applied to SRL specifically.
